{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "p0-YhEpP_Ds-",
        "yKnpwE3kmqSC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# Homework 3, Question 2\n",
        "## Implementing PageRank and HITS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive2\n",
        "#the output 'xxx is not a symbolic link' will not affect your implementation or execution\n",
        "#to fix 'xxx is not a symbolic link', you can uncomment the lines starting from !mv xxxx\n",
        "#you may need to replace xxx.11 with the correct version if other errors come up after colab update\n",
        "#to get the correct version, use !ls /usr/local/lib to find out\n",
        "!mv /usr/local/lib/libtbbmalloc_proxy.so.2 /usr/local/lib/libtbbmalloc_proxy.so.2.backup\n",
        "!mv /usr/local/lib/libtbbmalloc.so.2 /usr/local/lib/libtbbmalloc.so.2.backup\n",
        "!mv /usr/local/lib/libtbbbind_2_5.so.3 /usr/local/lib/libtbbbind_2_5.so.3.backup\n",
        "!mv /usr/local/lib/libtbb.so.12 /usr/local/lib/libtbb.so.12.backup\n",
        "!mv /usr/local/lib/libtbbbind_2_0.so.3 /usr/local/lib/libtbbbind_2_0.so.3.backup\n",
        "!mv /usr/local/lib/libtbbbind.so.3 /usr/local/lib/libtbbbind.so.3.backup\n",
        "!ln -s /usr/local/lib/libtbbmalloc_proxy.so.2.11 /usr/local/lib/libtbbmalloc_proxy.so.2\n",
        "!ln -s /usr/local/lib/libtbbmalloc.so.2.11 /usr/local/lib/libtbbmalloc.so.2\n",
        "!ln -s /usr/local/lib/libtbbbind_2_5.so.3.11 /usr/local/lib/libtbbbind_2_5.so.3\n",
        "!ln -s /usr/local/lib/libtbb.so.12.11 /usr/local/lib/libtbb.so.12\n",
        "!ln -s /usr/local/lib/libtbbbind_2_0.so.3.11 /usr/local/lib/libtbbbind_2_0.so.3\n",
        "!ln -s /usr/local/lib/libtbbbind.so.3.11 /usr/local/lib/libtbbbind.so.3\n",
        "#If error related to the above execution occurs, you can try commenting out the above 12 lines under pip install PyDrive2 (not included)\n",
        "\n",
        "# !sudo ldconfig\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTH2ERtRnHEd",
        "outputId": "93666d81-5f51-4f01-9d32-57b6681e3d58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=e30a30b2fcbf28a40ef38a8da0abfb16c1bf737fd83e08ee4d6c512fb794e619\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m821.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hThe following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRElWs_x2mGh"
      },
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "source": [
        "id='1Qm0rNAE-X3eiqhHb8nK7KcnipV61voNH'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('graph-small.txt')\n",
        "\n",
        "id='1G3WFiu1X8Wb6PE6Di0V_EFHY4vxAEQwB'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('graph-full.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's import the libraries we will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.types import DoubleType, ArrayType, FloatType"
      ],
      "metadata": {
        "id": "ZDapZhM8nB6L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "hNAmuNyrnT33"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) PageRank Implementation - Sanity check with a smaller dataset, graph-small.txt"
      ],
      "metadata": {
        "id": "O-fAaMtmmh7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"graph-small.txt\")\n",
        "\n",
        "# Create a list of all egdes\n",
        "data = data.map(lambda x : list(int(i) for i in x.split('\\t'))).collect()\n",
        "\n",
        "# List of unique edges\n",
        "edges = []\n",
        "for edge in data:\n",
        "    if edge not in edges:\n",
        "        edges.append(edge)\n",
        "\n",
        "edgesRDD = sc.parallelize(edges)"
      ],
      "metadata": {
        "id": "6_iXnhHdtGfm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of nodes\n",
        "nodesRDD = edgesRDD.flatMap(lambda edge: edge).distinct()\n",
        "\n",
        "# Create a dictionary to store the outgoing degree of each node\n",
        "out_degree_dict = edgesRDD.map(lambda edge: (edge[0], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
        "\n",
        "# Function to calculate the matrix element\n",
        "def calculate_matrix_element(edge):\n",
        "    source, dest = edge\n",
        "    out_degree = out_degree_dict.get(source)\n",
        "    if out_degree == 0:\n",
        "        return (dest, source, 0.0)\n",
        "    else:\n",
        "        return (dest, source, 1 / out_degree)\n",
        "\n",
        "# Calculate matrix elements in a form of (i, j, el)\n",
        "matrix_elementsRDD = edgesRDD.map(lambda edge : calculate_matrix_element(edge))\n",
        "\n",
        "# Create a dictionary of matrix elements of form of (i, j) : el\n",
        "matrix_elements_dict = {(i, j): el for (i, j, el) in matrix_elementsRDD.collect()}"
      ],
      "metadata": {
        "id": "pjrOVQwBwFyE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create matrix elements with default value 0 for missing elements\n",
        "def create_matrix(index_tuple):\n",
        "    i, j = index_tuple\n",
        "    el = matrix_elements_dict.get((i, j), 0)\n",
        "    return i, j, el\n",
        "\n",
        "# Create a matrix of all indices i, j from 1 to 100 and store them in RDD as (i, j, el)\n",
        "indices = sc.parallelize([(i, j) for i in range(1, 101) for j in range(1, 101)])\n",
        "matrix_elementsRDD = indices.map(lambda index : create_matrix(index)).map(lambda x : (x[0], x[1], x[2]))"
      ],
      "metadata": {
        "id": "OkrVNBVR9e81"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 100-by-100 matrix and store it as RDD\n",
        "matrix = [[0] * 100 for _ in range(100)]\n",
        "for i, j, el in matrix_elementsRDD.collect():\n",
        "    matrix[i - 1][j - 1] = el\n",
        "\n",
        "matrixRDD = sc.parallelize(matrix)"
      ],
      "metadata": {
        "id": "w8wUFjQMQodU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial vector r\n",
        "r = [1/100] * 100\n",
        "\n",
        "# Set beta to 0.8\n",
        "beta = 0.8\n",
        "n = 100\n",
        "\n",
        "# Perform matrix-vector multiplication\n",
        "def iteration(v1, v2):\n",
        "    result = (1 - beta) / n\n",
        "    for i, j in zip(v1, v2):\n",
        "        result += beta * i * j\n",
        "    return result\n",
        "\n",
        "# Iterate 40 times\n",
        "for _ in range(40):\n",
        "  r = matrixRDD.map(lambda line: iteration(line, r)).collect()\n",
        "\n",
        "np.array(r).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8qe1nUYQzLA",
        "outputId": "b14e3d11-ec58-48c0-e9c5-ab724f311e83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r[52]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOhRnMh1U6H0",
        "outputId": "0f24113b-2b90-446d-c1f8-50b7fd589b9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03573120223267159"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) PageRank Implementation"
      ],
      "metadata": {
        "id": "CFYCpg0zi890"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"graph-full.txt\")\n",
        "\n",
        "# Create a list of all egdes\n",
        "data = data.map(lambda x : list(int(i) for i in x.split('\\t'))).collect()\n",
        "\n",
        "# List of unique edges\n",
        "edges = []\n",
        "for edge in data:\n",
        "    if edge not in edges:\n",
        "        edges.append(edge)\n",
        "\n",
        "edgesRDD = sc.parallelize(edges)"
      ],
      "metadata": {
        "id": "chImvAzojivh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of nodes\n",
        "nodesRDD = edgesRDD.flatMap(lambda edge: edge).distinct()\n",
        "\n",
        "# Create a dictionary to store the outgoing degree of each node\n",
        "out_degree_dict = edgesRDD.map(lambda edge: (edge[0], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
        "\n",
        "# Calculate matrix elements in a form of (i, j, el)\n",
        "matrix_elementsRDD = edgesRDD.map(lambda edge : calculate_matrix_element(edge))\n",
        "\n",
        "# Create a dictionary of matrix elements of form of (i, j) : el\n",
        "matrix_elements_dict = {(i, j): el for (i, j, el) in matrix_elementsRDD.collect()}"
      ],
      "metadata": {
        "id": "70lqt0BLjm9W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix of all indices i, j from 1 to 1000 and store them in RDD as (i, j, el)\n",
        "indices = sc.parallelize([(i, j) for i in range(1, 1001) for j in range(1, 1001)])\n",
        "matrix_elementsRDD = indices.map(lambda index : create_matrix(index)).map(lambda x : (x[0], x[1], x[2]))"
      ],
      "metadata": {
        "id": "J9lG3FUmjtys"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1000-by-1000 matrix and store it as RDD\n",
        "matrix = [[0] * 1000 for _ in range(1000)]\n",
        "for i, j, el in matrix_elementsRDD.collect():\n",
        "    matrix[i - 1][j - 1] = el\n",
        "\n",
        "matrixRDD = sc.parallelize(matrix)"
      ],
      "metadata": {
        "id": "qUUPgABSj3Bb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial vector of all ones\n",
        "r = [1/1000] * 1000\n",
        "\n",
        "# Set beta to 0.8\n",
        "beta = 0.8\n",
        "n = 1000\n",
        "\n",
        "# Perform matrix-vector multiplication\n",
        "def iteration(v1, v2):\n",
        "    result = (1 - beta) / n\n",
        "    for i, j in zip(v1, v2):\n",
        "        result += beta * i * j\n",
        "    return result\n",
        "\n",
        "for _ in range(40):\n",
        "  r = matrixRDD.map(lambda line: iteration(line, r)).collect()"
      ],
      "metadata": {
        "id": "nPNb4bZxj7ET"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_list = [(el, idx) for idx, el in enumerate(r)]\n",
        "sorted_list = sorted(indexed_list, key=lambda x: x[0], reverse=True)\n",
        "indices_of_max_elements = sorted_list[:5]\n",
        "indices_of_min_elements = sorted_list[-5:]"
      ],
      "metadata": {
        "id": "GYbifNmskOZv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_max_elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSAhlrnNkhp7",
        "outputId": "b35e246d-ef0d-4653-b032-93778b9bf990"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0020202911815182193, 262),\n",
              " (0.0019433415714531503, 536),\n",
              " (0.001925447807166263, 964),\n",
              " (0.0018526340162417312, 242),\n",
              " (0.0018273721700645148, 284)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_min_elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ2_stvwki0D",
        "outputId": "fbd9f115-93cb-48bd-86b8-703d5e2c7cd5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.00038779848719291705, 407),\n",
              " (0.00035481538649301454, 423),\n",
              " (0.0003531481051059628, 61),\n",
              " (0.00035135689375165774, 92),\n",
              " (0.0003286018525215297, 557)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) HITS Implementation - Sanity check with a smaller dataset, graph-small.txt"
      ],
      "metadata": {
        "id": "yKnpwE3kmqSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"graph-small.txt\")\n",
        "\n",
        "# Create a list of all egdes\n",
        "data = data.map(lambda x : list(int(i) for i in x.split('\\t'))).collect()\n",
        "\n",
        "# List of unique edges\n",
        "edges = []\n",
        "for edge in data:\n",
        "    if edge not in edges:\n",
        "        edges.append(edge)\n",
        "\n",
        "edgesRDD = sc.parallelize(edges).map(lambda x : (x[0], x[1], 1))"
      ],
      "metadata": {
        "id": "s2MWMm5emxRZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of matrix elements of form of (i, j) : el\n",
        "matrix_elements_dict = {(i, j): el for (i, j, el) in edgesRDD.collect()}"
      ],
      "metadata": {
        "id": "f3J9bEoyp2M8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix of all indices i, j from 1 to 100 and store them in RDD as (i, j, el)\n",
        "indices = sc.parallelize([(i, j) for i in range(1, 101) for j in range(1, 101)])\n",
        "matrix_elementsRDD = indices.map(lambda index : create_matrix(index)).map(lambda x : (x[0], x[1], x[2]))"
      ],
      "metadata": {
        "id": "Vvjgr3sUqRkI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 100-by-100 matrix and store it as RDD\n",
        "matrix = [[0] * 100 for _ in range(100)]\n",
        "for i, j, el in matrix_elementsRDD.collect():\n",
        "    matrix[i - 1][j - 1] = el\n",
        "\n",
        "matrixRDD = sc.parallelize(matrix)"
      ],
      "metadata": {
        "id": "1txMbVTGqlkx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transpose = [list(x) for x in np.array(matrix).T]\n",
        "transposeRDD = sc.parallelize(transpose)"
      ],
      "metadata": {
        "id": "13m4qEGiu093"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product(v1, v2):\n",
        "    result = 0\n",
        "    for i, j in zip(v1, v2):\n",
        "        result += i * j\n",
        "    return result"
      ],
      "metadata": {
        "id": "D32XLNYtxVum"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial vector h\n",
        "h = [1] * 100\n",
        "\n",
        "for _ in range(40):\n",
        "    # Compute vector a and scale so the largest value in the vector a has value 1\n",
        "    a = transposeRDD.map(lambda line: dot_product(line, h))\n",
        "    m_a = a.max()\n",
        "    a = a.map(lambda x : x / m_a).collect()\n",
        "\n",
        "    # Compute vector h and scale so the largest value in the vector h has value 1\n",
        "    h = matrixRDD.map(lambda line: dot_product(line, a))\n",
        "    m_h = h.max()\n",
        "    h = h.map(lambda x : x / m_h).collect()"
      ],
      "metadata": {
        "id": "ib__0E94y_xD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(h).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuAiv9CK0zQf",
        "outputId": "d1614a94-0cc7-45e4-8b6e-a2547dcabd22"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(a).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na7J0qadBmyZ",
        "outputId": "7bbf7b37-db49-401b-892a-d3f501c778ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) HITS Implementation"
      ],
      "metadata": {
        "id": "3FVi0KjKBz4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_elementsRDD.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMPp0j2Q-YB5",
        "outputId": "476af8cb-ae5a-46a8-dd3a-b95a3a34390f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 0), (1, 2, 1), (1, 3, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"graph-full.txt\")\n",
        "\n",
        "# Create a list of all egdes\n",
        "data = data.map(lambda x : list(int(i) for i in x.split('\\t'))).collect()\n",
        "\n",
        "# List of unique edges\n",
        "edges = []\n",
        "for edge in data:\n",
        "    if edge not in edges:\n",
        "        edges.append(edge)\n",
        "\n",
        "edgesRDD = sc.parallelize(edges).map(lambda x : (x[0], x[1], 1))\n",
        "\n",
        "# Create a dictionary of matrix elements of form of (i, j) : el\n",
        "matrix_elements_dict = {(i, j): el for (i, j, el) in edgesRDD.collect()}\n",
        "\n",
        "# Create a matrix of all indices i, j from 1 to 1000 and store them in RDD as (i, j, el)\n",
        "indices = sc.parallelize([(i, j) for i in range(1, 1001) for j in range(1, 1001)])\n",
        "matrix_elementsRDD = indices.map(lambda index : create_matrix(index)).map(lambda x : (x[0], x[1], x[2]))\n",
        "\n",
        "# Create 1000-by-1000 matrix and store it as RDD\n",
        "matrix = [[0] * 1000 for _ in range(1000)]\n",
        "for i, j, el in matrix_elementsRDD.collect():\n",
        "    matrix[i - 1][j - 1] = el\n",
        "\n",
        "matrixRDD = sc.parallelize(matrix)\n",
        "\n",
        "# Transpose of matrix\n",
        "transpose = [list(x) for x in np.array(matrix).T]\n",
        "transposeRDD = sc.parallelize(transpose)\n",
        "\n",
        "# Initial vector h\n",
        "h = [1] * 100\n",
        "\n",
        "for _ in range(40):\n",
        "    # Compute vector a and scale so the largest value in the vector a has value 1\n",
        "    a = transposeRDD.map(lambda line: dot_product(line, h))\n",
        "    m_a = a.max()\n",
        "    a = a.map(lambda x : x / m_a).collect()\n",
        "\n",
        "    # Compute vector h and scale so the largest value in the vector h has value 1\n",
        "    h = matrixRDD.map(lambda line: dot_product(line, a))\n",
        "    m_h = h.max()\n",
        "    h = h.map(lambda x : x / m_h).collect()"
      ],
      "metadata": {
        "id": "OfBwnUoBB7go"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_list = [(el, idx) for idx, el in enumerate(h)]\n",
        "sorted_list = sorted(indexed_list, key=lambda x: x[0], reverse=True)\n",
        "indices_of_max_elements_h = sorted_list[:5]\n",
        "indices_of_min_elements_h = sorted_list[-5:]"
      ],
      "metadata": {
        "id": "UYSpB46_CTRI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_max_elements_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKR-1ahrCpo6",
        "outputId": "897ac3d2-d04d-466d-e39d-e6dd920c4795"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 839),\n",
              " (0.949961862490654, 154),\n",
              " (0.8986645288972263, 233),\n",
              " (0.8634171101843793, 388),\n",
              " (0.8632841092495216, 471)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_min_elements_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGuGH2CZCqct",
        "outputId": "9f75687b-cf59-44e5-f66a-2cf82121f0cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.07678413939216452, 888),\n",
              " (0.0660265937341849, 538),\n",
              " (0.06453117646225179, 140),\n",
              " (0.05779059354433016, 834),\n",
              " (0.042066854890936534, 22)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_list = [(el, idx) for idx, el in enumerate(a)]\n",
        "sorted_list = sorted(indexed_list, key=lambda x: x[0], reverse=True)\n",
        "indices_of_max_elements_a = sorted_list[:5]\n",
        "indices_of_min_elements_a = sorted_list[-5:]"
      ],
      "metadata": {
        "id": "1jOOnnc-CYfy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_max_elements_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FmeRI4TCsXO",
        "outputId": "bbc961cb-e1c6-4e0a-9cd2-780216793eef"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 892),\n",
              " (0.96355728496344, 15),\n",
              " (0.9510158161074022, 798),\n",
              " (0.9246703586198445, 145),\n",
              " (0.8998661973604051, 472)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_of_min_elements_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78TB287KCuQ3",
        "outputId": "50e8806f-081c-472a-af45-8051f23833b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.08571673456144879, 909),\n",
              " (0.08171239406816946, 23),\n",
              " (0.07544228624641902, 461),\n",
              " (0.06653910487622794, 134),\n",
              " (0.0560831637760762, 18)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}